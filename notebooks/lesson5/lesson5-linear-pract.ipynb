{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение и майнинг данных\n",
    "\n",
    "## 16/02/2017 Линейные модели, практика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим данные по кредитованию.\n",
    "\n",
    "Столбец с классом называется `y`.<br/> Значение $1$ соответствует классу клиентов банка, которым выдали кредит и они его успешно вернули.<br/> Значение $-1$ соответствует клиентам, невыполнившим свои кредитные обязанности. \n",
    "\n",
    "В банке хотят уметь определять по признакам `a1-a15`, сможет ли новый клиент вернуть кредит или нет? То есть нам надо обучить классификатор! *Обычно, в банках используют скор-карты, но процесс их построения тесно связан с логистической регрессией*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные и преобразуйте признаки `a1`, `a9`, `a10` и `a12` из строковых в числовые. В них только 2 возможных значения. Для этого можно использовать функцию DataFrame.replace() в `pandas` или самое обычное присваивание на соответствующих строках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('crx.data')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Заполнение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполните пропуски в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Преобразование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В признаках `a6`, `a7` присутствуют \"редкие\" значение. Найдите их с помощью фунцкии `.value_counts()`  и объедините, присвоив им одно и то же значение, например `'Other'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделите бинарные признаки `a1`, `a9`, `a10` и `a12` в матрицу `X_binary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На занятиях мы изучатли преобразование категориальных признаков с помощью комбинации `LabelEncoder` и `OneHotEncoder` или метода `pd.get_dummies`. <br\\>\n",
    "\n",
    "Есть еще один способ из библиотеки sklearn - `DictVectorizer`. Если хотите - можете разобраться, что делает код ниже, изучая промежуточные результаты каждой из команд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "dv.fit(df[['a5', 'a6', 'a7', 'a13']].T.to_dict().values())\n",
    "\n",
    "X_cat = dv.transform(df[['a5', 'a6', 'a7', 'a13']].T.to_dict().values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_cat` - эквивалентна последовательному применению `LabelEncoder` к каждому признаку `a5`, `a6`, `a7`, `a13` и использованию `OneHotEncoder`. Чтобы узнать, чему соответствует каждый столбец матрицы `X_cat` используйте команду `dv.feature_names_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы долнжы увидеть список с элементами вида <Признак>=<Значение>. Если в каком-то из случаев это не так, то\n",
    "* Либо `DictVectorizer` посчитал, что признак - не категориальный\n",
    "* Либо в признаке есть пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода  df[..].corr() убедитесь, что признаки `a2`, `a3`, `a8`, `a11`, `a14` и `a15` довольно слабо коррелируют друг с другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализуйте количественные признаки `a2`, `a3`, `a8`, `a11`, `a14` и `a15` с помощью `StandartScaler` или вручную. Вы должны получить матрицу `X_real`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте функцию `np.concatinate(..)` или `np.c[..]` чтобы сцепить матрицы `X_binary`, `X_cat` и `X_real`\n",
    "\n",
    "В результате вы должны получить матрицу с преобразованными призанками `X` и вектор ответов `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо мультиколлинеарности логистическая регрессия так же может быть подвержена переобучению. Как правило, на деле это выражается в \n",
    "* Очень больших весах $|w_i|$ при признаках\n",
    "* Неустойчивости решения (особенно в случае мультиколлинеарности, когда возникает линейная зависимость признаков и получается целое семейство равнозначных моделей)\n",
    "* Большая разница в качестве на обучении и валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регуляризация - это техника понижения \"сложности\" модели с минимальными последствиями для её качества."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае с логистичесткой регресии, сложность модели выражается в значениях весов $w_j$ при признаках. Больший вес означает большее влияние признака на результат. В таком случае, давайте добавил штрафное слагаемое в функцию оптимизации для логистической регресии. Самый распространенные из них это:\n",
    "\n",
    "* Ridge regression\n",
    "$$L(w) = - \\left(\\sum_i \\log(\\sigma(y^{(i)} \\langle w, x^{(i)} \\rangle)) + \\frac{1}{C}\\sum_j w_j^2\\right) \\rightarrow \\min_w$$\n",
    "\n",
    "* Lasso regression\n",
    "$$L(w) = -\\left(\\sum_i \\log(\\sigma(y^{(i)} \\langle w, x^{(i)} \\rangle) + \\frac{1}{C}\\sum_j |w_j|\\right) \\rightarrow \\min_w$$\n",
    "\n",
    "$C$ - называется гиперпараметром регуляризации и он задается вручную. Выбирается он с помощью кросс-валидации. Чем больше $С$ - тем меньше влияние регуляризации.\n",
    "\n",
    "Lasso regression называется так, потому что она осуществляет \"отлов\" признаков - т.е. незначимые признаки будут иметь нулевые веса в модели, в то время как в Ridge regression - веса будут постепенно падать у всех признаков.\n",
    "\n",
    "<img src='http://webdancer.is-programmer.com/user_files/webdancer/Image/lasso.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако использование регуляризации превращает логистическую регрессию в черный ящик - мы предоставляем оптимизационному методу решать за нас, какие признаки важны для модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сравним работу регуляризаторов. \n",
    "\n",
    "1. Разбейте данные на обучающую и контрольную выборки.\n",
    "1. Для $C$ из набора np.logspace(-3, 3, 10) обучите LogisctigRegression c Lasso регуляризацией (`penalty='l1'`). На каждой итерации оцените качество (ROC-AUC) на контрольной выборке и запомните полученные коэффициенты модели\n",
    "1. На одном графике выведите значение качества в зависимости от параметра `C` \n",
    "1. На другом графике для каждого признака выведите изменение коэффициента в модели в зависимости от параметра `C`\n",
    "1. Для оптимальной на ваш взгляд настройки модели выведите 5 наиболие \"важных\" признаков и их коэффициенты\n",
    "1. Проделайте тоже самое для Ridge регуляризации (`penalty='l2'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот так (примерно) выглядит скор-карта на выдачу кредита"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.mathworks.com/help/finance/credit_score_card_overview.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый \"признак\" разбит на бины (bins) - значимые интервалы. Если значение признака попадает в интервал, то к скору заемщика прибавляется сооветвтвующая величина.\n",
    "\n",
    "Таким образом формируется итоговый скор и далее принимается решение о выдаче кредита."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка порого бинов для признаков - это отдельная наука. Скоррингисты используют так называемое IV (information value) для оценки качества разбиения признака на бины."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На прошлом занятии мы изучили с вами другой способ выявления порогов на признаках - деревья решений (случайный лес). Почему бы нам это не использовать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "* Разбейте выборку на 2 части (обучение и контроль)\n",
    "* На половине обучающей выборке обучите случайный лес\n",
    "* С помощью метода `rand_forest.apply(X)` можно получить матрицу размера $n \\times t$, где $t$ - количество деревьев в лесу. В эту матрицу будет числом записан номер листа, в который попал объект\n",
    "* One-Hot Encoding!\n",
    "* Обучите логистическую регрессию на второй половине обучающей выборки\n",
    "* Сравние roc-auc на обычной лог-регрессии, обычного случайного леса и их композиции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Квадратичная ошибка достаточно чувствительна к выбросам. Давайте вернемся к нашим данным про автомобили и добавим туда выбросы.\n",
    "\n",
    "Посмотрим, как поведет себя простая линейная регрессия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('http://bit.ly/1gIQs6C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.mileage.values.reshape(-1, 1)\n",
    "y_train = df_train.price.values\n",
    "\n",
    "n = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Добавляем выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.r_[X_train, [[250000+np.random.rand()*10000]]]\n",
    "y_train = np.r_[y_train, 16000+np.random.randn()*1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train[:n], y_train[:n])\n",
    "\n",
    "model_ouliers = LinearRegression(fit_intercept=True)\n",
    "model_ouliers.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, max(X_train), 100).reshape(-1, 1)\n",
    "y_hat = model.predict(x)\n",
    "y_hat_outliers = model_ouliers.predict(x)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax.scatter(X_train, y_train)\n",
    "\n",
    "ax.plot(x, y_hat, c='red')\n",
    "ax.plot(x, y_hat_outliers, c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANSAC регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея метода RANdom SAmple Consensus (RANSAC) заключается в многократном обучении модели на случайном наборе точек из исходных данных с последующим выбором лучшей модели.\n",
    "\n",
    "То есть:\n",
    "* Задаем функцию потерь\n",
    "* Задаем порог $\\theta$ для остатков при котором наблюдения начинают относится к выбросам\n",
    "* Задаем правило останова\n",
    "\n",
    "Шаги алгоритма следующие\n",
    "1. Взять случайные K точек и обучить на них модель M\n",
    "2. Сравнить ошибки на остальных точких с порогом $\\theta$ и отнести к выбросам или внутренним точкам\n",
    "3. Обучить модель на всех внутренних точках, оценить качество на внутренних точках\n",
    "4. Повторить 1-3 пока не наступит правило останова. \n",
    "5. Вывод: модель с лучшим качеством"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ransac = RANSACRegressor(LinearRegression())\n",
    "model_ransac.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, max(X_train), 100).reshape(-1, 1)\n",
    "y_hat = model_ransac.predict(x)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax.scatter(X_train, y_train)\n",
    "\n",
    "ax.plot(x, y_hat, c='red')\n",
    "ax.plot(x, y_hat_outliers, c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея робастных методов заключается во взвешивании остатков модели таким образом, чтобы большие значения вносили меньший вклад в оценку параметров.\n",
    "\n",
    "Таким образом, вместо минимизации квадрата остатков $$ L(\\beta_0,\\beta_1,\\dots) = \\frac{1}{2n}\\sum^{n}_{i=1}(\\hat{y}^{(i)} - y^{(i)})^2$$\n",
    "Будут минимизироваться взвешенные остатки $$ L_w(\\beta_0,\\beta_1,\\dots) = \\frac{1}{2n}\\sum^{n}_{i=1}\\rho(\\hat{y}^{(i)} - y^{(i)}),$$\n",
    "где $\\rho(\\cdot)$ - некоторая взвешивающая функция.\n",
    "\n",
    "Для того, чтобы попробовать эти методы нужно будет устновить пакет `statsmodels` через `pip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 4.685\n",
    "support = np.linspace(-3*c, 3*c, 1000)\n",
    "tukey = sm.robust.norms.TukeyBiweight(c=c)\n",
    "plt.plot(support, tukey(support))\n",
    "plt.ylim(.1, -4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_robust = sm.RLM(y_train, sm.add_constant(X_train), M=sm.robust.norms.TukeyBiweight())\n",
    "model_robust = model_robust.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_robust.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, max(X_train), 100).reshape(-1, 1)\n",
    "y_hat = model_robust.predict(sm.add_constant(x))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax.scatter(X_train, y_train)\n",
    "\n",
    "ax.plot(x, y_hat, c='red')\n",
    "ax.plot(x, y_hat_outliers, c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного практики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [данные](http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv) о лесных пожарах в некоторых областях парка Montesinho в Португалии.\n",
    "\n",
    "Описание данных следующее:\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "3. month - month of the year: 'jan' to 'dec'\n",
    "4. day - day of the week: 'mon' to 'sun'\n",
    "5. FFMC - FFMC index from the FWI system: 18.7 to 96.20\n",
    "6. DMC - DMC index from the FWI system: 1.1 to 291.3\n",
    "7. DC - DC index from the FWI system: 7.9 to 860.6\n",
    "8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "10. RH - relative humidity in %: 15.0 to 100\n",
    "11. wind - wind speed in km/h: 0.40 to 9.40\n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4\n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84 \n",
    "\n",
    "Описание индексов FFMC, DMC, CD, ISI приводится [здесь](http://cwfis.cfs.nrcan.gc.ca/background/summary/fwi)\n",
    "\n",
    "Ваша задача - по данным признакам 1-12 предсказать признак 13, площадь области, которая подвергнется пожару."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем как приступать с модели, постройте гистрограмму площади пожара `area`. Что можно сказать о том, как распределены значения? Рассмотрите различные преобразования, например `log(area+1)` или `sqrt(area)` и выберите то, которое будет лучше использовать для предсказания (линейной моделью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Преобразование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполните преобразование признаков, а именно:\n",
    "\n",
    "* Нормализацию вещественных признаков с помощью z-score (x - x.mean())/x.std(). Нормализацию зависимой переменной `area` выполнять не надо.\n",
    "* Преобразование номинальных признаков `month` и `day` в числовое представление.\n",
    "* Имеет ли смысл преобразование для признаков `X` и `Y`? Если да - выполните его.\n",
    "\n",
    "\n",
    "На выходе вы должны получить матрицы X_train и X_test с преобразованными признаками, а так же векторы ответов y_train и y_test.ь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите две модели:\n",
    "\n",
    "* Простую линейную регрессию `LinearRegression` (без регуляризации). Выберите такое подмножество признаков из X_train, чтобы избежать мультиколлинеарности.\n",
    "* Любую другую понравившеюся вам модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчитайте предсказания для контролькой выборки. \n",
    "\n",
    "* Найдите среднюю абсолютную ошибку модели на контрольной выборке\n",
    "* Постройте график зависимости ошибок $|(\\text{area}) - (\\text{predicted_area})|$ и значений признака $\\text{area}$, где $\\text{area}$ и $\\text{predicted_area}$ - значения в исходной шкале, а не преобзованной после задания 2.1\n",
    "* Какие значения модель предсказывает лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##  Your Code Here"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc_position": {
   "height": "698px",
   "left": "0px",
   "right": "1217.33px",
   "top": "107px",
   "width": "212px"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
